{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6410112-2af6-4c79-ba92-a9ec22c0edf1",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "Pre-requisites: \n",
    "Have user start vllm server  in a different terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f964d8",
   "metadata": {},
   "source": [
    "# Burger Seller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ab65615-f43c-4fa9-bd16-311101909793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from pydantic import BaseModel\n",
    "import uuid\n",
    "from crewai import Agent, Crew, LLM, Task, Process\n",
    "from crewai.tools import tool\n",
    "from dotenv import load_dotenv\n",
    "import litellm\n",
    "# litellm.vertex_project = os.getenv(\"GCLOUD_PROJECT_ID\")\n",
    "# litellm.vertex_location = os.getenv(\"GCLOUD_LOCATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3f3e5dc-46ee-4f2b-af36-fa2eb6acfa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_BASE=\"http://localhost:8088/v1\" # vLLM serve URL (we used port 8088 here)\n",
    "VLLM_MODEL=\"hosted_vllm/meta-llama/Llama-3.1-8B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78b43ba4-9782-412f-b714-6e4be2221b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseFormat(BaseModel):\n",
    "    \"\"\"Respond to the user in this format.\"\"\"\n",
    "\n",
    "    status: Literal[\"input_required\", \"completed\", \"error\"] = \"input_required\"\n",
    "    message: str\n",
    "\n",
    "\n",
    "class OrderItem(BaseModel):\n",
    "    name: str\n",
    "    quantity: int\n",
    "    price: int\n",
    "\n",
    "\n",
    "class Order(BaseModel):\n",
    "    order_id: str\n",
    "    status: str\n",
    "    order_items: list[OrderItem]\n",
    "\n",
    "\n",
    "@tool(\"create_order\")\n",
    "def create_burger_order(order_items: list[OrderItem]) -> str:\n",
    "    \"\"\"\n",
    "    Creates a new burger order with the given order items.\n",
    "\n",
    "    Args:\n",
    "        order_items: List of order items to be added to the order.\n",
    "\n",
    "    Returns:\n",
    "        str: A message indicating that the order has been created.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        order_id = str(uuid.uuid4())\n",
    "        order = Order(order_id=order_id, status=\"created\", order_items=order_items)\n",
    "        print(\"===\")\n",
    "        print(f\"order created: {order}\")\n",
    "        print(\"===\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating order: {e}\")\n",
    "        return f\"Error creating order: {e}\"\n",
    "    return f\"Order {order.model_dump()} has been created\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "972af52d",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "class BurgerSellerAgent:\n",
    "    TaskInstruction = \"\"\"\n",
    "# INSTRUCTIONS\n",
    "\n",
    "You are a specialized assistant for a burger store.\n",
    "Your sole purpose is to answer questions about what is available on burger menu and price also handle order creation.\n",
    "If the user asks about anything other than burger menu or order creation, politely state that you cannot help with that topic and can only assist with burger menu and order creation.\n",
    "Do not attempt to answer unrelated questions or use tools for other purposes.\n",
    "\n",
    "# CONTEXT\n",
    "\n",
    "Received user query: {user_prompt}\n",
    "Session ID: {session_id}\n",
    "\n",
    "Provided below is the available burger menu and it's related price:\n",
    "- Classic Cheeseburger: IDR 85K\n",
    "- Double Cheeseburger: IDR 110K\n",
    "- Spicy Chicken Burger: IDR 80K\n",
    "- Spicy Cajun Burger: IDR 85K\n",
    "\n",
    "# RULES\n",
    "\n",
    "- If user want to do something, you will be following this order:\n",
    "    1. Always ensure the user already confirmed the order and total price. This confirmation may already given in the user query.\n",
    "    2. Use `create_burger_order` tool to create the order\n",
    "    3. Finally, always provide response to the user about the detailed ordered items, price breakdown and total, and order ID\n",
    "    \n",
    "- Set response status to input_required if asking for user order confirmation.\n",
    "- Set response status to error if there is an error while processing the request.\n",
    "- Set response status to completed if the request is complete.\n",
    "- DO NOT make up menu or price, Always rely on the provided menu given to you as context.\n",
    "\"\"\"\n",
    "    SUPPORTED_CONTENT_TYPES = [\"text\", \"text/plain\"]\n",
    "\n",
    "    def invoke(self, query, sessionId) -> str:\n",
    "        burger_agent = Agent(\n",
    "            role=\"Burger Seller Agent\",\n",
    "            goal=(\n",
    "                \"Help user to understand what is available on burger menu and price also handle order creation.\"\n",
    "            ),\n",
    "            backstory=(\"You are an expert and helpful burger seller agent.\"),\n",
    "            verbose=False,\n",
    "            allow_delegation=False,\n",
    "            tools=[create_burger_order],\n",
    "            llm=LLM(\n",
    "                model=\"hosted_vllm/meta-llama/Llama-3.1-8B-Instruct\", # os.getenv(\"VLLM_MODEL\"), #VLLM_MODEL\n",
    "                api_base=\"http://localhost:8088/v1\" # os.getenv(\"OPENAI_API_BASE\") # OPENAI_API_BASE\n",
    "                )\n",
    "        )\n",
    "\n",
    "        agent_task = Task(\n",
    "            description=self.TaskInstruction,\n",
    "            output_pydantic=ResponseFormat,\n",
    "            agent=burger_agent,\n",
    "            expected_output=(\n",
    "                \"A JSON object with 'status' and 'message' fields.\"\n",
    "                \"Set response status to input_required if asking for user order confirmation.\"\n",
    "                \"Set response status to error if there is an error while processing the request.\"\n",
    "                \"Set response status to completed if the request is complete.\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        crew = Crew(\n",
    "            tasks=[agent_task],\n",
    "            agents=[burger_agent],\n",
    "            verbose=False,\n",
    "            process=Process.sequential,\n",
    "        )\n",
    "\n",
    "        inputs = {\"user_prompt\": query, \"session_id\": sessionId}\n",
    "        response = crew.kickoff(inputs)\n",
    "        return self.get_agent_response(response)\n",
    "\n",
    "    def get_agent_response(self, response):\n",
    "        response_object = response.pydantic\n",
    "        if response_object and isinstance(response_object, ResponseFormat):\n",
    "            if response_object.status == \"input_required\":\n",
    "                return {\n",
    "                    \"is_task_complete\": False,\n",
    "                    \"require_user_input\": True,\n",
    "                    \"content\": response_object.message,\n",
    "                }\n",
    "            elif response_object.status == \"error\":\n",
    "                return {\n",
    "                    \"is_task_complete\": False,\n",
    "                    \"require_user_input\": True,\n",
    "                    \"content\": response_object.message,\n",
    "                }\n",
    "            elif response_object.status == \"completed\":\n",
    "                return {\n",
    "                    \"is_task_complete\": True,\n",
    "                    \"require_user_input\": False,\n",
    "                    \"content\": response_object.message,\n",
    "                }\n",
    "\n",
    "        return {\n",
    "            \"is_task_complete\": False,\n",
    "            \"require_user_input\": True,\n",
    "            \"content\": \"We are unable to process your request at the moment. Please try again.\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa71119a-a558-4042-9d8d-598d2ddb6c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copyright 2025 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\"\"\"\n",
    "\n",
    "from a2a_server.server import A2AServer\n",
    "from a2a_types import AgentCard, AgentCapabilities, AgentSkill, AgentAuthentication\n",
    "from a2a_server.push_notification_auth import PushNotificationSenderAuth\n",
    "from task_manager import AgentTaskManager\n",
    "from agent import BurgerSellerAgent\n",
    "import click\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import threading\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "\n",
    "AUTH_USERNAME=\"burgeruser123\"\n",
    "AUTH_PASSWORD=\"burgerpass123\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b35708b-7ca0-4baa-a8f2-bad8e22bf27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(host, port):\n",
    "    \"\"\"Starts the Burger Seller Agent server.\"\"\"\n",
    "    try:\n",
    "        capabilities = AgentCapabilities(pushNotifications=True)\n",
    "        skill = AgentSkill(\n",
    "            id=\"create_burger_order\",\n",
    "            name=\"Burger Order Creation Tool\",\n",
    "            description=\"Helps with creating burger orders\",\n",
    "            tags=[\"burger order creation\"],\n",
    "            examples=[\"I want to order 2 classic cheeseburgers\"],\n",
    "        )\n",
    "        agent_card = AgentCard(\n",
    "            name=\"burger_seller_agent\",\n",
    "            description=\"Helps with creating burger orders\",\n",
    "            # The URL provided here is for the sake of demo,\n",
    "            # in production you should use a proper domain name\n",
    "            url=f\"http://{host}:{port}/\",\n",
    "            version=\"1.0.0\",\n",
    "            authentication=AgentAuthentication(schemes=[\"Basic\"]),\n",
    "            defaultInputModes=BurgerSellerAgent.SUPPORTED_CONTENT_TYPES,\n",
    "            defaultOutputModes=BurgerSellerAgent.SUPPORTED_CONTENT_TYPES,\n",
    "            capabilities=capabilities,\n",
    "            skills=[skill],\n",
    "        )\n",
    "\n",
    "\n",
    "        notification_sender_auth = PushNotificationSenderAuth()\n",
    "        notification_sender_auth.generate_jwk()\n",
    "        server = A2AServer(\n",
    "            agent_card=agent_card,\n",
    "            task_manager=AgentTaskManager(\n",
    "                agent=BurgerSellerAgent(),\n",
    "                notification_sender_auth=notification_sender_auth,\n",
    "            ),\n",
    "            host=host,\n",
    "            port=port,\n",
    "            auth_username=AUTH_USERNAME,\n",
    "            auth_password=AUTH_PASSWORD,\n",
    "        )\n",
    "\n",
    "        server.app.add_route(\n",
    "            \"/.well-known/jwks.json\",\n",
    "            notification_sender_auth.handle_jwks_endpoint,\n",
    "            methods=[\"GET\"],\n",
    "        )\n",
    "\n",
    "        logger.info(f\"Starting server on {host}:{port}\")\n",
    "        server.start()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during server startup: {e}\")\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "869e7532-cc6e-4f83-a457-d1cdb7214342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting server on 0.0.0.0:10001\n",
      "INFO:     Started server process [432068]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:10001 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server thread started. Waiting a moment for server to initialize on http://0.0.0.0:10001\n"
     ]
    }
   ],
   "source": [
    "# --- Global variable to hold the server thread reference ---\n",
    "# This allows you to stop it later from another cell if needed\n",
    "global server_thread\n",
    "server_thread = None\n",
    "\n",
    "# --- Main execution in the Jupyter cell ---\n",
    "if server_thread is not None and server_thread.is_alive():\n",
    "    print(\"Server is already running.\")\n",
    "else:\n",
    "    # Define host and port\n",
    "    server_host = \"0.0.0.0\"\n",
    "    server_port = 10001\n",
    "\n",
    "    # Create and start the thread\n",
    "    server_thread = threading.Thread(target=main, args=(server_host, server_port))\n",
    "    server_thread.daemon = True # Allows the main program to exit even if the thread is still running\n",
    "    server_thread.start()\n",
    "\n",
    "    print(f\"Server thread started. Waiting a moment for server to initialize on http://{server_host}:{server_port}\")\n",
    "    time.sleep(5) # Give it a few seconds to boot up\n",
    "\n",
    "    # You can now proceed with other cells, or client code in this cell\n",
    "    # Example client interaction (assuming your server exposes an endpoint)\n",
    "    # import requests\n",
    "    # try:\n",
    "    #     response = requests.get(f\"http://127.0.0.1:{server_port}/\") # Or your specific endpoint\n",
    "    #     response.raise_for_status()\n",
    "    #     print(f\"Successfully connected to server. Status: {response.status_code}\")\n",
    "    #     # print(\"Server root response:\", response.text)\n",
    "    # except requests.exceptions.ConnectionError:\n",
    "    #     print(f\"Error: Could not connect to the server at http://127.0.0.1:{server_port}/. Is it running?\")\n",
    "    # except Exception as e:\n",
    "    #     print(f\"An error occurred during client connection: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a130f4d-ce41-4aae-9022-20bba37460e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<agent.BurgerSellerAgent object at 0x7e5154342d20>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m agent = BurgerSellerAgent()\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(agent) \n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m result = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m1 classic cheeseburger pls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdefault_session\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/purchasing-concierge-a2a/remote_seller_agents/burger_agent/agent.py:118\u001b[39m, in \u001b[36mBurgerSellerAgent.invoke\u001b[39m\u001b[34m(self, query, sessionId)\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\u001b[38;5;28mself\u001b[39m, query, sessionId) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    109\u001b[39m     burger_agent = Agent(\n\u001b[32m    110\u001b[39m         role=\u001b[33m\"\u001b[39m\u001b[33mBurger Seller Agent\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    111\u001b[39m         goal=(\n\u001b[32m    112\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mHelp user to understand what is available on burger menu and price also handle order creation.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    113\u001b[39m         ),\n\u001b[32m    114\u001b[39m         backstory=(\u001b[33m\"\u001b[39m\u001b[33mYou are an expert and helpful burger seller agent.\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    115\u001b[39m         verbose=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    116\u001b[39m         allow_delegation=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    117\u001b[39m         tools=[create_burger_order],\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m         llm=\u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mVLLM_MODEL\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#VLLM_MODEL\u001b[39;49;00m\n\u001b[32m    120\u001b[39m \u001b[43m            \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOPENAI_API_BASE\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# OPENAI_API_BASE\u001b[39;49;00m\n\u001b[32m    121\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m     )\n\u001b[32m    124\u001b[39m     agent_task = Task(\n\u001b[32m    125\u001b[39m         description=\u001b[38;5;28mself\u001b[39m.TaskInstruction,\n\u001b[32m    126\u001b[39m         output_pydantic=ResponseFormat,\n\u001b[32m   (...)\u001b[39m\u001b[32m    133\u001b[39m         ),\n\u001b[32m    134\u001b[39m     )\n\u001b[32m    136\u001b[39m     crew = Crew(\n\u001b[32m    137\u001b[39m         tasks=[agent_task],\n\u001b[32m    138\u001b[39m         agents=[burger_agent],\n\u001b[32m    139\u001b[39m         verbose=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    140\u001b[39m         process=Process.sequential,\n\u001b[32m    141\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/purchasing-concierge-a2a/.venv/lib/python3.12/site-packages/crewai/llm.py:297\u001b[39m, in \u001b[36mLLM.__init__\u001b[39m\u001b[34m(self, model, timeout, temperature, top_p, n, stop, max_completion_tokens, max_tokens, presence_penalty, frequency_penalty, logit_bias, response_format, seed, logprobs, top_logprobs, base_url, api_base, api_version, api_key, callbacks, reasoning_effort, stream, **kwargs)\u001b[39m\n\u001b[32m    295\u001b[39m \u001b[38;5;28mself\u001b[39m.reasoning_effort = reasoning_effort\n\u001b[32m    296\u001b[39m \u001b[38;5;28mself\u001b[39m.additional_params = kwargs\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m \u001b[38;5;28mself\u001b[39m.is_anthropic = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_is_anthropic_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[38;5;28mself\u001b[39m.stream = stream\n\u001b[32m    300\u001b[39m litellm.drop_params = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/purchasing-concierge-a2a/.venv/lib/python3.12/site-packages/crewai/llm.py:323\u001b[39m, in \u001b[36mLLM._is_anthropic_model\u001b[39m\u001b[34m(self, model)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Determine if the model is from Anthropic provider.\u001b[39;00m\n\u001b[32m    315\u001b[39m \n\u001b[32m    316\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    320\u001b[39m \u001b[33;03m    bool: True if the model is from Anthropic, False otherwise.\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    322\u001b[39m ANTHROPIC_PREFIXES = (\u001b[33m\"\u001b[39m\u001b[33manthropic/\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mclaude-\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mclaude/\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mANTHROPIC_PREFIXES\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/purchasing-concierge-a2a/.venv/lib/python3.12/site-packages/crewai/llm.py:323\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Determine if the model is from Anthropic provider.\u001b[39;00m\n\u001b[32m    315\u001b[39m \n\u001b[32m    316\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    320\u001b[39m \u001b[33;03m    bool: True if the model is from Anthropic, False otherwise.\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    322\u001b[39m ANTHROPIC_PREFIXES = (\u001b[33m\"\u001b[39m\u001b[33manthropic/\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mclaude-\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mclaude/\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28many\u001b[39m(prefix \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m() \u001b[38;5;28;01mfor\u001b[39;00m prefix \u001b[38;5;129;01min\u001b[39;00m ANTHROPIC_PREFIXES)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "agent = BurgerSellerAgent()\n",
    "print(agent) \n",
    "result = agent.invoke(\"1 classic cheeseburger pls\", \"default_session\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082c5488",
   "metadata": {},
   "source": [
    "1) Learn how to utilize Google ADK on AMD GPUs with your own models.\n",
    "2) Step-by-step instructions for setting up a Google ADK Agentic AI application locally.\n",
    "3) Explore next steps to leverage AMD Developer Cloud resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e30667b",
   "metadata": {},
   "source": [
    "Have user "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910f3b84-ed93-4c67-bddf-35bdd9dc3cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305bec9e-2630-447b-b907-e5cc5d23a791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "purchasing_concierge",
   "language": "python",
   "name": "purchasing_concierge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
